<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Agnibh Dasgupta — AI Researcher</title>
  <meta name="description" content="AI researcher focusing on invariant representations, robust watermarking, and LLM/VLM robustness." />
  <style>
    :root{
      --bg: #0b0f14; --fg:#e6eef8; --muted:#a8b3c7; --card:#121922; --accent:#84aef0; --accent-2:#8be9c4; --border:#1e2835;
      --max: 1100px;
    }
    *{box-sizing:border-box}
    html, body{margin:0; padding:0; background:var(--bg); color:var(--fg); font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";}
    a{color:var(--accent); text-decoration:none}
    a:hover{text-decoration:underline}
    .wrap{max-width:var(--max); margin:0 auto; padding:24px}
    header{display:flex; gap:18px; align-items:center; justify-content:space-between; padding:18px 0; border-bottom:1px solid var(--border)}
    nav a{margin-left:18px; font-weight:600}
    .hero{display:grid; grid-template-columns: 1.3fr 1fr; gap:24px; padding:32px 0}
    .hero h1{font-size: clamp(28px, 4vw, 44px); line-height:1.1; margin:8px 0}
    .hero p{color:var(--muted); font-size: clamp(16px, 2vw, 18px)}
    .tag{display:inline-block; padding:6px 10px; border:1px solid var(--border); border-radius:999px; color:var(--muted); font-size:13px}
    .cards{display:grid; grid-template-columns:repeat(auto-fill, minmax(260px,1fr)); gap:16px}
    .card{background:var(--card); border:1px solid var(--border); border-radius:16px; padding:18px}
    .card h3{margin:0 0 6px 0; font-size:18px}
    .card p{margin:0; color:var(--muted); font-size:15px}
    .section{padding:28px 0; border-top:1px solid var(--border)}
    h2{font-size:22px; margin:0 0 14px 0}
    .pubs li{margin:14px 0;}
    .pubs .venue{color:var(--muted); font-style:italic}
    .grid-2{display:grid; grid-template-columns: 1fr 1fr; gap:24px}
    footer{padding:28px 0; color:var(--muted); border-top:1px solid var(--border); margin-top:28px}
    .btn{display:inline-block; background:linear-gradient(135deg, var(--accent), var(--accent-2)); color:#0a0e14; font-weight:700; padding:10px 14px; border-radius:12px}
    .mono{font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace; font-size: 13px; color:var(--muted)}
    ul{padding-left:20px}
    @media (max-width: 860px){ .hero{grid-template-columns:1fr} header{flex-wrap:wrap} }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <div style="display:flex; align-items:center; gap:14px">
        <div style="width:44px;height:44px;border-radius:12px;background:linear-gradient(135deg,var(--accent),var(--accent-2));filter:brightness(1.2)"></div>
        <div>
          <div style="font-weight:800; letter-spacing:0.2px">Agnibh Dasgupta</div>
          <div class="mono">AI Researcher · PhD (Information Science & Technology)</div>
        </div>
      </div>
      <nav>
        <a href="#about">About</a>
        <a href="#research">Research</a>
        <a href="#publications">Publications</a>
        <a href="#projects">Projects</a>
        <a href="#contact">Contact</a>
      </nav>
    </header>

    <section class="hero">
      <div>
        <span class="tag">Invariant Representations · Watermarking · LLM/VLM Robustness</span>
        <h1>Building robust, invariant representations for vision and language models</h1>
        <p>
          I study how models encode meaning that remains stable under perturbations—data augmentations for images and paraphrases for language. My work spans
          robust image watermarking (cross-attention + invariant domain learning), auto-augmentation, and identifying invariant latent features in LLMs/VLMs for attribution and forensics.
        </p>
        <div style="margin-top:16px; display:flex; gap:10px; flex-wrap:wrap">
          <a class="btn" href="#publications">View Publications</a>
          <a class="btn" style="background:transparent; border:1px solid var(--border); color:var(--fg)" href="https://github.com/cent664" target="_blank" rel="noopener">GitHub</a>
          <a class="btn" style="background:transparent; border:1px solid var(--border); color:var(--fg)" href="#cv">CV</a>
        </div>
      </div>
      <div class="card">
        <h3>At a glance</h3>
        <ul>
          <li>PhD candidate (UNO); focus: invariant feature learning</li>
          <li>Research areas: robust watermarking, auto-augmenters, LLM attribution</li>
          <li>Interests: ViT-based vision, self-supervision, multimodal robustness</li>
        </ul>
        <div style="margin-top:12px">
          <div class="mono">Actively seeking 2026 research scientist roles (US & abroad)</div>
        </div>
      </div>
    </section>

    <section id="about" class="section">
      <h2>About</h2>
      <div class="grid-2">
        <div>
          <p>
            I'm a doctoral researcher in Information Science &amp; Technology at the University of Nebraska Omaha. My dissertation centers on <strong>Invariant Domain Learning</strong> and its applications to <strong>robust image watermarking</strong> and <strong>LLM/VLM robustness</strong>.
          </p>
          <p>
            Broadly, I design systems that remain stable under content-preserving transformations: geometric/photometric augmentations for images and
            lexical/structural paraphrases for text. I care about <em>what</em> a model knows versus <em>how</em> it encodes it.
          </p>
        </div>
        <div class="card">
          <h3>Research interests</h3>
          <ul>
            <li>Invariant representations &amp; stability under augmentations</li>
            <li>Robust watermarking (vision &amp; language)</li>
            <li>Adversarial/auto-augmentation</li>
            <li>LLM/VLM attribution &amp; forensics</li>
            <li>Self-supervised learning (contrastive/InfoNCE)</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="research" class="section">
      <h2>Selected research</h2>
      <div class="cards">
        <article class="card">
          <h3>Robust Image Watermarking via Cross-Attention &amp; Invariant Domain Learning</h3>
          <p class="venue">CSCI 2023</p>
          <p>Watermark embedding/extraction resilient to geometric &amp; photometric attacks using ViT features aligned to an invariant subspace.</p>
          <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="#" aria-label="code">Code</a></p>
        </article>
        <article class="card">
          <h3>Auto-Augmenter for Adversarial Robustness in Representation Learning</h3>
          <p class="venue">In preparation</p>
          <p>Learned augmentation policy that stresses encoders; evaluates stability via classification and feature-similarity objectives.</p>
          <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="#" aria-label="code">Code</a></p>
        </article>
        <article class="card">
          <h3>Invariant Latent Features for LLM Attribution (LLMID)</h3>
          <p class="venue">Preprint</p>
          <p>Layer-wise analysis to identify paraphrase-stable features in LLMs; supports semantic grouping &amp; model attribution.</p>
          <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="#" aria-label="code">Code</a></p>
        </article>
      </div>
    </section>

    <section id="publications" class="section">
      <h2>Publications &amp; preprints</h2>
      <ul class="pubs">
        <li>
          <strong>Leveraging Artificial Intelligence (AI) to Enhance K-12 Computer Science (CS)</strong> — <span class="venue">FIE 2024</span><br/>
          <span class="mono">Authors: A. Dasgupta, et al.</span>
        </li>
        <li>
          <strong>Robust Image Watermarking based on Cross-Attention and Invariant Domain Learning</strong> — <span class="venue">CSCI 2023</span><br/>
          <span class="mono">Authors: A. Dasgupta, et al.</span>
        </li>
        <li>
          <strong>Watermarking Language Models through Language Models</strong> — <span class="venue">IEEE TAI (under review/accepted — update)</span><br/>
          <span class="mono">Authors: A. Dasgupta, et al.</span>
        </li>
        <li>
          <strong>Other works</strong> — SAM2 retinal leakage segmentation (AAO), invariant-domain watermarking extensions, and more.
        </li>
      </ul>
      <p class="mono">Tip: replace placeholders above with actual author lists, links (PDF/ArXiv/DOI), and venues.</p>
    </section>

    <section id="projects" class="section">
      <h2>Open-source projects</h2>
      <div class="cards">
        <article class="card">
          <h3>Watermarking-ID</h3>
          <p>End-to-end ViT watermarking pipeline with invariant-domain features and key-based extraction. Robust to common augments.</p>
          <p><a href="https://github.com/cent664" target="_blank" rel="noopener">GitHub</a></p>
        </article>
        <article class="card">
          <h3>AutoAugmenter</h3>
          <p>Differentiable augmenter with photometric &amp; geometric modules; adversarially trains encoders for stability.</p>
          <p><a href="https://github.com/cent664" target="_blank" rel="noopener">GitHub</a></p>
        </article>
        <article class="card">
          <h3>LLMID</h3>
          <p>Layer-wise invariance analysis for LLM paraphrase robustness and model attribution.</p>
          <p><a href="https://github.com/cent664" target="_blank" rel="noopener">GitHub</a></p>
        </article>
      </div>
    </section>

    <section id="cv" class="section">
      <h2>CV</h2>
      <p>Add a <span class="mono">/cv/Agnibh_Dasgupta_CV.pdf</span> and link it here.</p>
    </section>

    <section id="contact" class="section">
      <h2>Contact</h2>
      <div class="grid-2">
        <div>
          <p>Email: <a href="mailto:adg002@gmail.com">agnibh@example.com</a></p>
          <p>GitHub: <a href="https://github.com/cent664" target="_blank" rel="noopener">cent664</a></p>
          <p>LinkedIn: <a href="https://www.linkedin.com/in/cent664/" target="_blank" rel="noopener">Add link</a></p>
          <p>Google Scholar: <a href="https://scholar.google.com/citations?user=LlBDprIAAAAJ&hl=en" target="_blank" rel="noopener">Add link</a></p>
        </div>
        <div class="card">
          <h3>One‑line bio</h3>
          <p class="mono">Invariant-domain learning for robust watermarking and LLM/VLM attribution.</p>
        </div>
      </div>
    </section>

    <footer>
      <div class="mono">© <span id="y"></span> Agnibh Dasgupta. Built with minimal HTML/CSS.
        <span style="float:right"><a href="#">Back to top</a></span>
      </div>
    </footer>
  </div>
  <script>document.getElementById('y').textContent = new Date().getFullYear()</script>
</body>
</html>
