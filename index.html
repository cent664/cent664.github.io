<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Agnibh Dasgupta — AI Researcher</title>
  <meta name="description" content="AI researcher focusing on representation learning, robust watermarking, and LLM robustness." />
  <style>
    :root {
      --bg: #0b0f14;
      --fg: #e6eef8;
      --muted: #a8b3c7;
      --card: #121922;
      --accent: #84aef0;
      --accent-2: #8be9c4;
      --border: #1e2835;
      --max: 1100px;
    }

    * { box-sizing: border-box; }

    html, body {
      margin: 0;
      padding: 0;
      background: var(--bg);
      color: var(--fg);
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
    }

    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }

    .wrap { max-width: var(--max); margin: 0 auto; padding: 24px; }

    header {
      display: flex;
      gap: 18px;
      align-items: center;
      justify-content: space-between;
      padding: 18px 0;
      border-bottom: 1px solid var(--border);
    }

    nav a { margin-left: 18px; font-weight: 600; }

    .hero {
      display: grid;
      grid-template-columns: 1.3fr 1fr;
      gap: 24px;
      padding: 32px 0;
    }

    .hero h1 {
      font-size: clamp(28px, 4vw, 44px);
      line-height: 1.1;
      margin: 8px 0;
    }

    .hero p {
      color: var(--muted);
      font-size: clamp(16px, 2vw, 18px);
    }

    .tag {
      display: inline-block;
      padding: 6px 10px;
      border: 1px solid var(--border);
      border-radius: 999px;
      color: var(--muted);
      font-size: 13px;
    }

    .cards {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(260px, 1fr));
      gap: 16px;
    }

    .card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 18px;
    }

    .card h3 { margin: 0 0 6px 0; font-size: 18px; }

    .card p { margin: 0; color: var(--muted); font-size: 15px; }

    .section {
      padding: 28px 0;
      border-top: 1px solid var(--border);
    }

    h2 { font-size: 22px; margin: 0 0 14px 0; }

    .pubs li { margin: 14px 0; }
    .pubs .venue { color: var(--muted); font-style: italic; }

    .grid-2 {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 24px;
    }

    footer {
      padding: 28px 0;
      color: var(--muted);
      border-top: 1px solid var(--border);
      margin-top: 28px;
    }

    .btn {
      display: inline-block;
      background: linear-gradient(135deg, var(--accent), var(--accent-2));
      color: #0a0e14;
      font-weight: 700;
      padding: 10px 14px;
      border-radius: 12px;
    }

    .mono {
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
      font-size: 13px;
      color: var(--muted);
    }

    ul { padding-left: 20px; }

    /* === Icon styling for CV & Contact section === */
    #cv-contact p {
      display: flex;
      align-items: center;
      gap: 8px;
      margin: 4px 0;
    }

    #cv-contact img {
      filter: invert(1);
      transition: filter 0.25s ease, transform 0.2s ease;
      width: 18px;
      height: 18px;
    }

    #cv-contact img:hover {
      filter: invert(69%) sepia(49%) saturate(447%) hue-rotate(192deg)
              brightness(95%) contrast(89%);
      transform: scale(1.05);
    }

    @media (max-width: 860px) {
      .hero { grid-template-columns: 1fr; }
      header { flex-wrap: wrap; }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <div style="display:flex; align-items:center; gap:18px">
        <img src="img/headshot.JPG"
             alt="Agnibh Dasgupta"
             style="
               width:180px;
               height:220px;
               border-radius:12px;
               object-fit:cover;
               border:2px solid var(--border);
               background:var(--card);
               box-shadow:0 0 6px rgba(0,0,0,0.4);
             ">
        <div>
          <div style="font-weight:800; letter-spacing:0.2px; font-size:20px;">Agnibh Dasgupta</div>
          <div class="mono" style="font-size:14px;">AI Researcher · PhD (Artificial Intelligence)</div>
        </div>
      </div>

      <nav>
        <a href="#about">About</a>
        <a href="#selected-research">Selected Research</a>
        <a href="#publications">Publications</a>
        <a href="#cv-contact">Contact</a>
      </nav>
    </header>


    <section class="hero">
      <div>
        <span class="tag">Representation Learning · Watermarking · LLM Robustness</span>
        <h1>Building robust, invariant representations for AI models</h1>
        <p>
          I study how models encode semantic meaning that remains stable under perturbations. My work spans robust representation learning for
          image watermarking, auto-augmentation, and identifying invariant latent features in LLMs for attribution and forensics.
        </p>
        <div style="margin-top:16px; display:flex; gap:10px; flex-wrap:wrap">
          <a class="btn" href="#publications">View Publications</a>
          <a class="btn" style="background:transparent; border:1px solid var(--border); color:var(--fg)" href="https://github.com/cent664" target="_blank" rel="noopener">GitHub</a>
          <a class="btn" style="background:transparent; border:1px solid var(--border); color:var(--fg)" href="#cv">CV</a>
        </div>
      </div>
      <div class="card">
        <h3>At a glance</h3>
        <ul>
          <li>PhD candidate at University of Nebraska - Omaha. Focus: Artificial Intelligence</li>
          <li>Research areas: representation learning, robust image watermarking, LLM watermarking and attribution</li>
          <li>Other Interests: Reinforcement learning, multimodalilty in deep learning </li>
        </ul>
        <div style="margin-top:12px">
          <div class="mono">Actively seeking 2026 research scientist roles</div>
        </div>
      </div>
    </section>


    <section id="about" class="section">
      <h2>About</h2>
      <div class="grid-2">
        <div>
          <p>
            I'm a doctoral researcher in Information Science &amp; Technology at the University of Nebraska Omaha. My dissertation centers on <strong>invariant representation learning</strong> and its applications to <strong>robust image watermarking</strong> and <strong>LLM robustness</strong>.
          </p>
          <p>
            Broadly, I design systems that remain stable under content-preserving transformations: geometric/photometric augmentations for images and
            lexical/structural paraphrases for text. I care about <em>what</em> an AI model knows versus <em>how</em> it encodes it.
          </p>
        </div>
        <div class="card">
          <h3>Research interests</h3>
          <ul>
            <li>Invariant representations &amp; stability under augmentations</li>
            <li>Robust watermarking (vision &amp; language)</li>
            <li>LLM attribution &amp; forensics</li>
            <li>Self-supervised learning</li>
          </ul>
        </div>
      </div>
    </section>


    <section id="selected-research" class="section">
      <h2>Selected Research</h2>
      <div style="display:flex; flex-direction:column; gap:32px;">

        <article class="card" style="display:flex; flex-direction:column; gap:16px; align-items:flex-start;">
          <img src="img/LLMWM.JPG" alt="Watermarking Language Models through Language Models" style="width:100%; height:200px; object-fit:cover; border-radius:12px; border:1px solid var(--border);">
          <div style="width:100%;">
            <h3>Watermarking Language Models through Language Models</h3>
            <p class="venue">IEEE Transactions on Artificial Intelligence (in press, 2025)</p>
            <p>Prompt-based LLM watermarking framework that embeds detectable signals in model responses without modifying weights or data. Evaluated watermark generation and detection using instruction-tuned LLMs.</p>
            <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="https://github.com/cent664/LLMWM" target="_blank" rel="noopener">GitHub</a></p>
          </div>
        </article>

        <article class="card" style="display:flex; flex-direction:column; gap:16px; align-items:flex-start;">
          <img src="img/SSRIW.png" alt="Robust Image Watermarking via Cross-Attention & Invariant Domain Learning" style="width:100%; height:200px; object-fit:cover; border-radius:12px; border:1px solid var(--border);">
          <div style="width:100%;">
            <h3>Robust Image Watermarking via Cross-Attention &amp; Invariant Domain Learning</h3>
            <p class="venue">CSCI 2023</p>
            <p>Watermark embedding and extraction method resilient to geometric and photometric attacks. Utilizes ViT-based cross-attention to align invariant domain features for robust watermark decoding.</p>
            <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="https://github.com/cent664/SSRIW" target="_blank" rel="noopener">GitHub</a></p>
          </div>
        </article>

        <article class="card" style="display:flex; flex-direction:column; gap:16px; align-items:flex-start;">
          <img src="img/llmid.jpg" alt="LLMID: Invariant Latent Features for LLM Attribution" style="width:100%; height:200px; object-fit:cover; border-radius:12px; border:1px solid var(--border);">
          <div style="width:100%;">
            <h3>LLMID: Invariant Latent Features for LLM Attribution</h3>
            <p class="venue">Preprint</p>
            <p>Layer-wise analysis framework for identifying paraphrase-stable latent representations in LLMs. Supports semantic clustering and model attribution tasks.</p>
            <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="https://github.com/cent664/LLMID" target="_blank" rel="noopener">GitHub</a></p>
          </div>
        </article>

        <article class="card" style="display:flex; flex-direction:column; gap:16px; align-items:flex-start;">
          <img src="img/autoaugment.jpg" alt="AutoAugmenter: Adversarial Robustness in Representation Learning" style="width:100%; height:200px; object-fit:cover; border-radius:12px; border:1px solid var(--border);">
          <div style="width:100%;">
            <h3>AutoAugmenter: Adversarial Robustness in Representation Learning</h3>
            <p class="venue">In preparation</p>
            <p>Differentiable augmentation framework that learns to adversarially perturb images to challenge encoders. Evaluates representation stability via classification and similarity-based objectives.</p>
            <p><a href="#" aria-label="paper pdf">PDF</a> · <a href="https://github.com/cent664/Autoaugment" target="_blank" rel="noopener">GitHub</a></p>
          </div>
        </article>

      </div>
    </section>


    <section id="publications" class="section">
      <h2>Publications</h2>
      <ul class="pubs">

        <li>
          <strong>Watermarking Language Models through Language Models</strong> — <span class="venue">IEEE Transactions on Artificial Intelligence, 2025</span><br/>
          <span class="mono">Authors: A. Dasgupta, A. Tanvir, X. Zhong</span><br/>
          <a href="#" target="_blank" rel="noopener">In press</a>
        </li>

        <li>
          <strong>Utilization of SAM2 Model for the Segmentation of Retinal Vascular Leakage on Ultra-wide-field Fluorescein Angiography in Non-infectious Retinal Vasculitis</strong> — <span class="venue">American Academy of Ophthalmology (AAO), 2025</span><br/>
          <span class="mono">Authors: X. Xing, I. Karaca, A. Akhavanrezayat, S. Badrloo, Q. D. Nguyen, M. Subramaniam</span><br/>
          <a href="https://arxiv.org/html/2509.10554v3" target="_blank" rel="noopener">arXiv</a>
        </li>

        <li>
          <strong>Enhanced Image Watermarking Through Cross-Attention and Noise-Invariant Domain Learning</strong> — <span class="venue">Imaging Science: Computer Vision, Image and Signal Processing Pattern Recognition, 2024</span><br/>
          <span class="mono">Authors: A. Dasgupta, X. Zhong</span><br/>
          <a href="https://ieeexplore.ieee.org/abstract/document/11052895" target="_blank" rel="noopener">IEEE Xplore</a>
        </li>

        <li>
          <strong>Leveraging Artificial Intelligence (AI) to Enhance CS Instruction</strong> — <span class="venue">Frontiers in Education (FIE), 2024</span><br/>
          <span class="mono">Authors: H. Yoon, X. Zhong, A. Dasgupta, G. Nugent, G. Trainin</span><br/>
          <a href="https://ieeexplore.ieee.org/document/10893354" target="_blank" rel="noopener">IEEE Xplore</a>
        </li>

        <li>
          <strong>Robust Image Watermarking based on Cross-Attention and Invariant Domain Learning</strong> — <span class="venue">CSCI 2023</span><br/>
          <span class="mono">Authors: A. Dasgupta, X. Zhong</span><br/>
          <a href="https://ieeexplore.ieee.org/document/10590390" target="_blank" rel="noopener">IEEE Xplore</a>
        </li>

        <li>
          <strong>Perspective Transformation Layer</strong> — <span class="venue">CSCI 2022</span><br/>
          <span class="mono">Authors: N. Khatri; A. Dasgupta; Y. Shen; X Zhong; F. Y. Shih</span><br/>
          <a href="https://ieeexplore.ieee.org/document/10216469" target="_blank" rel="noopener">IEEE Xplore</a>
        </li>

      </ul>

      <p class="mono">Links to papers in press will be updated as they become available.</p>
    </section>


    <section id="cv-contact" class="section">
      <h2>CV &amp; Contact</h2>
      <div style="display:flex; flex-direction:column; gap:6px; font-size:15px; line-height:1.4;">
        <p><a href="Agnibh_Dasgupta_CV.pdf" target="_blank" rel="noopener"><strong>View CV (PDF)</strong></a></p>
        <p style="display:flex; align-items:center; gap:8px;">
          <img src="https://cdn.jsdelivr.net/npm/simple-icons@v10/icons/maildotru.svg"
               alt="Email" width="18" height="18" style="filter:invert(1);">
          <a href="mailto:adg002@gmail.com">adg002@gmail.com</a>
        </p>
        <p style="display:flex; align-items:center; gap:8px;">
          <img src="https://cdn.jsdelivr.net/npm/simple-icons@v10/icons/github.svg" alt="GitHub" width="18" height="18" style="filter:invert(1);">
          <a href="https://github.com/cent664" target="_blank" rel="noopener">cent664</a>
        </p>
        <p style="display:flex; align-items:center; gap:8px;">
          <img src="https://cdn.jsdelivr.net/npm/simple-icons@v10/icons/linkedin.svg" alt="LinkedIn" width="18" height="18" style="filter:invert(1);">
          <a href="https://www.linkedin.com/in/cent664/" target="_blank" rel="noopener">linkedin.com/in/cent664</a>
        </p>
        <p style="display:flex; align-items:center; gap:8px;">
          <img src="https://cdn.jsdelivr.net/npm/simple-icons@v10/icons/googlescholar.svg" alt="Google Scholar" width="18" height="18" style="filter:invert(1);">
          <a href="https://scholar.google.com/citations?user=LlBDprIAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar Profile</a>
        </p>
      </div>
    </section>


    <footer>
      <div class="mono">© <span id="y"></span> Agnibh Dasgupta. Built with minimal HTML/CSS.
        <span style="float:right"><a href="#">Back to top</a></span>
      </div>
    </footer>
  </div>
  <script>document.getElementById('y').textContent = new Date().getFullYear()</script>
</body>
</html>
